{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Convolutional Neural Network\n",
    "\n",
    "\n",
    "Welcome to your fourth (last) assignment. You will train a convolutional neural network to classify images in this assignment. \n",
    "\n",
    "## Exercises:\n",
    "1. $\\color{violet}{\\textbf{(10\\%) Data Loading}}$\n",
    "2. $\\color{violet}{\\textbf{(30\\%) ConvNet Creation}}$\n",
    "4. $\\color{violet}{\\textbf{(50\\%) Training}}$\n",
    "5. $\\color{violet}{\\textbf{(10\\%) Evaluation}}$\n",
    "\n",
    "## Instructions:\n",
    "- Write your code only between the $\\color{green}{\\textbf{\\small \\#\\#\\# START CODE HERE \\#\\#\\#}}$ and $\\color{green}{\\textbf{\\small \\#\\#\\# END CODE HERE \\#\\#\\#}}$ commented lines. $\\color{red}{\\textbf{Do not modify code out of the designated area.}}$\n",
    "- This assignment was originated from one of the [PyTorch Tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). \n",
    "\n",
    "**You will learn:**\n",
    "\n",
    "how to use PyTorch on\n",
    "1. Loading built-in datasets and creating dataloaders \n",
    "2. Defining a Convolutional Neural Network\n",
    "3. Defining a loss functions and an optimizer\n",
    "4. Training a model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "For this assignment, we will use the CIFAR10 dataset.\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
    "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
    "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "\n",
    "### $\\color{violet}{\\textbf{(10\\%) Exercise 1: Data Loading}}$\n",
    "1. Use `torchvision.datasets` to load CIFAR10 dataset into `train_set` and `test_set`.\n",
    "2. Use `torch.utils.data.DataLoader` to create dataloaders for training data: `dataloader_train` and test data: `dataloader_test`.\n",
    "3. Remeber to apply transforms on `train_set` and `test_set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "transform = v2.Compose([v2.ToTensor(), v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # transform PILImage images of range [0, 255] to Tensors of normalized range [0, 1].\n",
    "batch_size = 64\n",
    "\n",
    "### START CODE HERE ### (≈ 4 lines of code)\n",
    "train_set = None\n",
    "dataloader_train = None\n",
    "test_set = None\n",
    "dataloader_test = None\n",
    "### END CODE HERE ### \n",
    "\n",
    "# Sanity check\n",
    "print('Training set has {} instances'.format(len(train_set)))\n",
    "print('Validation set has {} instances'.format(len(test_set)))\n",
    "classes = train_set.classes\n",
    "print(f\"dataset categories: {classes}\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "data_iterator = iter(dataloader_train)  \n",
    "images, labels = next(data_iterator)  # get a batch of random training data\n",
    "imshow(torchvision.utils.make_grid(images[:5]))  # display 5 samples\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(5)))  # print classes of corresponding images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting\n",
    "    the num_worker of torch.utils.data.DataLoader() to 0.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Convolutional Neural Network\n",
    "\n",
    "### $\\color{violet}{\\textbf{(30\\%) Exercise 2: ConvNet Creation}}$\n",
    "1. Use four convolution kernels to transform images.\n",
    "2. The 1st convolution kernel has size of (3, 3), and stride of (2, 2). It will output 32 channels of features tensors with shape (32, 15, 15).\n",
    "3. The 2nd convolution kernel has size of (3, 3), and stride of (2, 2). It will output 64 channels of features tensors with shape (64, 7, 7).\n",
    "4. The 3rd convolution kernel has size of (3, 3), and stride of (1, 1). It will output 128 channels of features tensors with shape (128, 5, 5).\n",
    "5. The 4th convolution kernel has size of (2, 2), and stride of (1, 1). It will output 128 channels of features tensors with shape (128, 4, 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        self.conv1 = None\n",
    "        self.conv2 = None\n",
    "        self.conv3 = None\n",
    "        self.conv4 = None\n",
    "        ### END CODE HERE ### \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 128)  # 64 channels * 4 horizontal features * 4 vertical features\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # (32 - 3) / 2 + 1 = 15.5\n",
    "        x = F.relu(self.conv2(x))  # (15 - 3) / 2 + 1 = 7\n",
    "        x = F.relu(self.conv3(x))  # (7 - 3) + 1 = 5\n",
    "        x = F.relu(self.conv4(x))  # (5 - 2) + 1 = 4\n",
    "        x = x.view(-1, 128 * 4 * 4) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "model = ConvNet().to(device)  # use GPU if available\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n",
    "### $\\color{violet}{\\textbf{(50\\%) Exercise 3: Training}}$\n",
    "1. Define a loss function for classification.\n",
    "2. Define an appropriate optimizer.\n",
    "3. Set a good learning rate for the optimizer.\n",
    "4. Set a good training epochs number.\n",
    "5. Make predictions.\n",
    "6. Compute loss.\n",
    "7. Compute gradient with back-propagation\n",
    "8. Update model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "model = ConvNet().to(device)  # Re-initialize model parameters\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "\n",
    "### START CODE HERE ### (≈ 4 lines of code)\n",
    "# Hyper-parameter setting\n",
    "loss_fn = None\n",
    "learning_rate = None\n",
    "optimizer = None\n",
    "num_epochs = None\n",
    "### END CODE HERE ###\n",
    "# Training loops\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    print(f\"----\\nEpoch: {epoch + 1}\")\n",
    "    model.train(True)\n",
    "    acc_loss_train = 0.0  # accumulated loss in an epoch\n",
    "    avg_loss_train = 0.0  # averaged loss in an epoch\n",
    "    for i, batch_train in enumerate(dataloader_train):\n",
    "        optimizer.zero_grad()\n",
    "        features_train, labels_train = batch_train[0].to(device), batch_train[1].to(device)  # get a batch of data; data is a list of [images, labels]\n",
    "        ### START CODE HERE ### (≈ 4 lines of code)\n",
    "        preds_train = None\n",
    "        loss_train = None\n",
    "        None  # back-propagation\n",
    "        None  # update params\n",
    "        ### END CODE HERE ###\n",
    "        # Statistics\n",
    "        acc_loss_train += loss_train.item()\n",
    "        if not i % 200:    # print loss every 200 batches\n",
    "            print(f\"[batch: {i + i}] training batch loss: {loss_train.item()}\")\n",
    "            # loss_train = 0.0\n",
    "    avg_loss_train = acc_loss_train / (i + 1)\n",
    "    losses_train.append(avg_loss_train)\n",
    "    print(f\"Averaged training loss: {avg_loss_train}\")\n",
    "    # Test\n",
    "    model.eval()\n",
    "    acc_loss_test = 0.\n",
    "    avg_loss_test = 0.\n",
    "    with torch.no_grad():\n",
    "        for i, batch_test in enumerate(dataloader_test):\n",
    "            features_test, labels_test = batch_test[0].to(device), batch_test[1].to(device)\n",
    "            preds_test = model(features_test)\n",
    "            loss_test = loss_fn(preds_test, labels_test)\n",
    "            acc_loss_test += loss_test.item()\n",
    "    avg_loss_test = acc_loss_test / (i + 1)\n",
    "    losses_test.append(avg_loss_test)\n",
    "    print(f\"Averaged test loss: {avg_loss_test}\\n\")\n",
    "\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses_train, '#818A8F', linewidth=1)\n",
    "plt.plot(losses_test, '#4F2D7F', linewidth=2.5)\n",
    "plt.legend(['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Convolutional Neural Network Model\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataiter = iter(dataloader_test)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "outputs = model(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('GroundTruth: \\n', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
    "print('Predicted: \\n', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results seem pretty good.\n",
    "\n",
    "Let us look at how the ConvNet model performs on the entire test dataset.\n",
    "\n",
    "### $\\color{violet}{\\textbf{(10\\%) Exercise 4: Model Accuracy}}$\n",
    "$\\color{red}{\\text{The overall test accuracy has to be greater than }\\textbf{65\\%}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_correct = 0\n",
    "num_total = 0\n",
    "with torch.no_grad():  # zero the parameter gradients\n",
    "    for data in dataloader_test:\n",
    "        features, labels = data[0].to(device), data[1].to(device)\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        preds = None  # predict images classes\n",
    "        _, pred_class_ids = None  # the class with the highest energy is what we choose as prediction\n",
    "        ### END CODE HERE ###\n",
    "        num_total += labels.size(0)\n",
    "        num_correct += (pred_class_ids == labels).sum().item()\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * num_correct / num_total}%')\n",
    "\n",
    "# Count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "with torch.no_grad():  # again no gradients needed\n",
    "    for data in dataloader_test:\n",
    "        features, labels = data[0].to(device), data[1].to(device)\n",
    "        preds = model(features)  # predict images classes\n",
    "        _, pred_class_ids = torch.max(preds, dim=1)\n",
    "        # collect the correct predictions for each class\n",
    "        for lb, pci in zip(labels, pred_class_ids):\n",
    "            if lb == pci:\n",
    "                correct_pred[classes[lb]] += 1\n",
    "            total_pred[classes[lb]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with New Images\n",
    "You are welcome to upload more pictures to `images/` folder and test your model out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torchvision.io import decode_image, read_image\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize(size=(32, 32)),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "img_origin = read_image(str(Path('./images') / 'hank.jpg'))  # change the file name\n",
    "img = transforms(img_origin).to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(img)\n",
    "pred_class_id = torch.argmax(pred)\n",
    "print(f\"Predicted class: {classes[pred_class_id]}\")\n",
    "imshow(img.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize original image\n",
    "plt.imshow(img_origin.numpy().transpose(1, 2, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats on finishing this assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3321",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
