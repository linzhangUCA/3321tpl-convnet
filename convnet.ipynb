{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Convolutional Neural Network\n",
        "\n",
        "**Due: Wednesday, 12/13/2023, 2:15 PM**\n",
        "\n",
        "Welcome to your fifth (last) assignment. You will train a convolutional neural network to classify images in this assignment. \n",
        "\n",
        "## Exercises:\n",
        "1. $\\color{violet}{\\textbf{(10\\%) Data Loading}}$\n",
        "2. $\\color{violet}{\\textbf{(30\\%) ConvNet Creation}}$\n",
        "3. $\\color{violet}{\\textbf{(20\\%) Loss Function and Optimizer}}$\n",
        "4. $\\color{violet}{\\textbf{(30\\%) Training}}$\n",
        "5. $\\color{violet}{\\textbf{(10\\%) Evaluation}}$\n",
        "\n",
        "## Instructions:\n",
        "- Write your code only between the $\\color{green}{\\textbf{\\small \\#\\#\\# START CODE HERE \\#\\#\\#}}$ and $\\color{green}{\\textbf{\\small \\#\\#\\# END CODE HERE \\#\\#\\#}}$ commented lines. $\\color{red}{\\textbf{Do not modify code out of the designated area.}}$\n",
        "- This assignment was originated from one of the [PyTorch Tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html). \n",
        "\n",
        "**You will learn:**\n",
        "\n",
        "how to use PyTorch on\n",
        "1. Loading built-in datasets and creating dataloaders \n",
        "2. Defining a Convolutional Neural Network\n",
        "3. Defining a loss functions and an optimizer\n",
        "4. Training a model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data\n",
        "For this assignment, we will use the CIFAR10 dataset.\n",
        "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,\n",
        "‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of\n",
        "size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "\n",
        "### $\\color{violet}{\\textbf{(10\\%) Exercise 1: Data Loading}}$\n",
        "1. Use `torchvision.datasets` to load CIFAR10 dataset into `train_set` and `test_set`.\n",
        "2. Use `torch.utils.data.DataLoader` to create dataloaders for training data: `dataloader_train` and test data: `dataloader_test`.\n",
        "3. Remeber to apply transforms on `train_set` and `test_set`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  # transform PILImage images of range [0, 255] to Tensors of normalized range [0, 1].\n",
        "batch_size = 64\n",
        "\n",
        "### START CODE HERE ### (≈ 4 lines of code)\n",
        "train_set = None\n",
        "dataloader_train = None\n",
        "test_set = None\n",
        "dataloader_test = None\n",
        "### END CODE HERE ### \n",
        "\n",
        "# Sanity check\n",
        "classes = train_set.classes\n",
        "print(f\"dataset categories: {classes}\")\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "data_iterator = iter(dataloader_train)  # get a batch of random training data\n",
        "images, labels = next(data_iterator)\n",
        "imshow(torchvision.utils.make_grid(images[:5]))  # display 5 samples\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(5)))  # print classes of corresponding images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting\n",
        "    the num_worker of torch.utils.data.DataLoader() to 0.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Create a Convolutional Neural Network\n",
        "\n",
        "### $\\color{violet}{\\textbf{(30\\%) Exercise 2: ConvNet Creation}}$\n",
        "1. Use two convolutional kernels.\n",
        "2. 1st convolutional kernel size should be (5, 5) and outputs 64 channels of features matrices.\n",
        "3. 2nd convolutional kernel size should be (3, 3) and outputs 128 channels of features matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "### START CODE HERE ### (≈ 2 lines of code)\n",
        "        self.conv1 = None\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = None\n",
        "### END CODE HERE ### \n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 128)  # 128 channels * 5 horizontal features * 5 vertical features\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 6\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = ConvNet().to(device)  # use GPU if available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Cross Entropy Loss and Optimizer\n",
        "Let's prepare a Classification Cross-Entropy loss function and a stochstic gradient descent (SGD) optimizer.\n",
        "\n",
        "### $\\color{violet}{\\textbf{(20\\%) Exercise 3: Loss Function and Optimizer}}$\n",
        "1. Use the right loss function class from `torch.nn`.\n",
        "2. Use the right optimizer class from `torch.optim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "### START CODE HERE ### (≈ 2 lines of code)\n",
        "loss_fn = None\n",
        "optimizer = None\n",
        "### END CODE HERE ###\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train the network\n",
        "\n",
        "This is when things start to get interesting.\n",
        "We simply have to loop over our data iterator, and feed the inputs to the\n",
        "network and optimize.\n",
        "\n",
        "### $\\color{violet}{\\textbf{(30\\%) Exercise 4: Training}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    loss_train = 0.0\n",
        "    for i, data in enumerate(dataloader_train, 0):\n",
        "        feature_train, target_train = data[0].to(device), data[1].to(device)  # get the inputs; data is a list of [inputs, labels]\n",
        "        optimizer.zero_grad()\n",
        "### START CODE HERE ### (≈ 4 lines of code)\n",
        "        pred_train = None\n",
        "        loss = None\n",
        "        None  # back-propagation\n",
        "        None  # update params\n",
        "### END CODE HERE ###\n",
        "        # print statistics\n",
        "        loss_train += loss.item()\n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] training loss: {loss_train / 200:.3f}')\n",
        "            loss_train = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluate the Convolutional Neural Network Model\n",
        "\n",
        "We have trained the network for 2 passes over the training dataset.\n",
        "But we need to check if the network has learnt anything at all.\n",
        "\n",
        "We will check this by predicting the class label that the neural network\n",
        "outputs, and checking it against the ground-truth. If the prediction is\n",
        "correct, we add the sample to the list of correct predictions.\n",
        "\n",
        "Okay, first step. Let us display an image from the test set to get familiar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataiter = iter(dataloader_test)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "outputs = model(images.to(device))\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(8)))\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(8)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results seem pretty good.\n",
        "\n",
        "Let us look at how the network performs on the whole dataset.\n",
        "\n",
        "### $\\color{violet}{\\textbf{(10\\%) Exercise 5: Evaluation}}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# Since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():  # zero the parameter gradients\n",
        "    for data in dataloader_test:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "### START CODE HERE ### (≈ 2 lines of code)\n",
        "        outputs = None  # predict images classes\n",
        "        _, predicted = None  # the class with the highest energy is what we choose as prediction\n",
        "### END CODE HERE ###\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n",
        "\n",
        "# Prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad():  # again no gradients needed\n",
        "    for data in dataloader_test:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Congrats on finishing this assignment!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
